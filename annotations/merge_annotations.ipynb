{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "merge_annotations.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOTIh1pOROJo"
      },
      "outputs": [],
      "source": [
        "# packages\n",
        "import csv\n",
        "from concurrent.futures import thread\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_marieke = pd.read_csv('marieke_s.csv')\n",
        "df_friso = pd.read_csv('friso_s.csv')\n",
        "df_robin = pd.read_csv('robin_s.csv')\n",
        "\n",
        "df_merged = pd.concat([df_marieke['thread_id'],\n",
        "                       df_marieke['comment_id'],\n",
        "                       df_marieke['sentence'],\n",
        "                       df_marieke['evidence'],\n",
        "                       df_friso['evidence'],\n",
        "                       df_robin['evidence']],\n",
        "                       axis=1)\n",
        "df_merged['gold_label'] = \"\"\n",
        "df_merged.columns = ['thread_id', 'comment_id', 'sentence', 'a1', 'a2', 'a3', 'gold_label']\n",
        "\n",
        "for index, row in df_merged.iterrows():\n",
        "    gold_label = \"\"\n",
        "    a1 = row['a1']\n",
        "    a2 = row['a2']\n",
        "    a3 = row['a3']\n",
        "    if a1 == 'Common ground':\n",
        "        a1 = 'Assumption'\n",
        "    if a2 == 'Common ground':\n",
        "        a2 = 'Assumption'\n",
        "    if a3 == 'Common ground':\n",
        "        a3 = 'Assumption'\n",
        "    if a1 == a2 or a1 == a3:\n",
        "        gold_label = a1\n",
        "    elif a2 == a3:\n",
        "        gold_label = a2\n",
        "    df_merged.at[index, 'gold_label'] = gold_label\n",
        "\n",
        "df_merged.to_csv('10threads.csv', index=False)"
      ],
      "metadata": {
        "id": "9utLKRkzWkXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remaining topics"
      ],
      "metadata": {
        "id": "7dtqabUsXCdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for remaining topics:\n",
        "# three final files\n",
        "files = [\"final_friso.csv\", \"final_marieke.csv\", \"final_robin.csv\"]\n",
        "# list for labels\n",
        "dataset = []\n",
        "# list for the first 10 topics to filter them out\n",
        "df = pd.read_csv('marieke.csv')\n",
        "thread_ids = list(set(df['thread_id'].tolist()))\n",
        "x = -1\n",
        "row = len(df.index)\n",
        "for fl in files:\n",
        "    # iterate through the three files\n",
        "    with open(fl) as f:\n",
        "        # reads file\n",
        "        csv_reader = csv.reader(f, delimiter=',')\n",
        "        # because friso's csv file is generated differently we need to\n",
        "        # set the index manually\n",
        "        for line in csv_reader:\n",
        "            # If line is the headers of a new file the line got skipped\n",
        "            # Or if the first 10 topics are in the file\n",
        "            if \"final_friso\" in fl:\n",
        "                i = 10\n",
        "            else:\n",
        "                i = 5\n",
        "            if line[0] == \"thread_id\" or line[0] in thread_ids or line[i] == \"Double\":\n",
        "                continue\n",
        "\n",
        "            # if there are somehow 2 labels for 1 sentence line is skipped\n",
        "            # (only for 4 sentences this is the case)\n",
        "            if not '{\"choices\":' in line[i]:\n",
        "                if not line[i] == \"\":\n",
        "                  df_merged.loc[row] = [line[0], line[1], line[2], \"\", \"\", \"\", line[i]]\n",
        "                  row +=1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X3_0YpzUXQjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Double Sentences"
      ],
      "metadata": {
        "id": "4hwQgnHCXBTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# appending the gold_label of the total disagreement\n",
        "# making a dict so we can add thread id and comment id as well\n",
        "dict = {}\n",
        "with open(\"marieke.csv\") as f:\n",
        "  csv_reader = csv.reader(f, delimiter=\",\")\n",
        "  for line in csv_reader:\n",
        "    if not line[2] == \"sentence\":\n",
        "      dict[line[2]] = (line[0], line[1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open(\"disagreement_fixed.csv\") as f:\n",
        "        csv_reader = csv.reader(f, delimiter=',')\n",
        "        for line in csv_reader:\n",
        "          if not line[0] == \"sentence\":\n",
        "            thread_id = dict[line[0]][0]\n",
        "            comment_id = dict[line[0]][1]\n",
        "            df_merged.loc[df_merged[\"sentence\"] == line[0]] = [thread_id, comment_id, line[0], line[1], line[2], line[3], line[4]]\n",
        "            row +=1\n"
      ],
      "metadata": {
        "id": "NpwCTZNhWXFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Total disagreement labels"
      ],
      "metadata": {
        "id": "yDJpvgyLhOa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"double_sentence_fixed.csv\") as f:\n",
        "        csv_reader = csv.reader(f, delimiter=',')\n",
        "        for line in csv_reader:\n",
        "            df_merged.loc[row] = [line[2], line[3], line[0], \"\", \"\", \"\", line[1]]\n",
        "            row +=1\n",
        "df_merged.to_csv('full_annotations.csv', index=False)\n",
        "y = df_merged[\"gold_label\"].tolist()\n",
        "df = df_merged.drop(df_merged[df_merged.gold_label == \"\"].index)\n",
        "# for index, row in df_merged.iterrows():\n",
        "#   if row[\"gold_label\"] == \"Continue\":\n",
        "#     df_merged.at[index, 'gold_label'] = df_merged.at[index-1, \"gold_label\"]\n",
        "\n",
        "df_merged.to_csv('dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "vJJ8xqWZhS4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JQcY9OJksL0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}